{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dpkt\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Packet:\n",
    "    '''Encapsulate TCP's header fields of a packet from pcap.\n",
    "    \n",
    "    Attributes:\n",
    "        source_port (int):  source port number\n",
    "        dest_port (int):    destination port number\n",
    "        sequence_num (int): sequence number\n",
    "        ack_num (int):      acknowledgement number\n",
    "        head_len(int):      header length\n",
    "        urg (int):          urgent flag\n",
    "        ack (int):          acknowledgement flag\n",
    "        psh (int):          psh flag\n",
    "        rst (int):          reset flag\n",
    "        syn (int):          synchronize flag\n",
    "        fin (int):          finish flag\n",
    "        receive_win (int):  receive window\n",
    "        checksum (int):     checksum\n",
    "        urgent (int):       urgent data pointer\n",
    "        scale (int):        window scaling size\n",
    "        size (int):         the size of the whole packet, including data and all headers\n",
    "        payload (int):      TCP payload\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, packet):\n",
    "        '''Init a packet\n",
    "        \n",
    "        Args:\n",
    "            packet(tuple): an element from dpkt.pcap.Reader.readpkts()\n",
    "        '''\n",
    "        self.time_stamp = packet[0]\n",
    "        self.byte_info  = packet[1]\n",
    "        self.size = len(packet[1])\n",
    "\n",
    "        \n",
    "    def parse_byte_info(self):\n",
    "        '''Convert the byte format information of a packet into human readable fields\n",
    "        '''\n",
    "        self.source_port  = int.from_bytes(self.byte_info[34:36], byteorder='big')\n",
    "        self.dest_port    = int.from_bytes(self.byte_info[36:38], byteorder='big')\n",
    "        self.sequence_num = int.from_bytes(self.byte_info[38:42], byteorder='big')\n",
    "        self.ack_num      = int.from_bytes(self.byte_info[42:46], byteorder='big')\n",
    "        head_len          = int.from_bytes(self.byte_info[46:47], byteorder='big')\n",
    "        self.head_len     = 4*(head_len>>4)\n",
    "        flags             = int.from_bytes(self.byte_info[47:48], byteorder='big')\n",
    "        self.fin = flags&1\n",
    "        flags = flags>>1\n",
    "        self.syn = flags&1\n",
    "        flags = flags>>1\n",
    "        self.rst = flags&1\n",
    "        flags = flags>>1\n",
    "        self.psh = flags&1\n",
    "        flags = flags>>1\n",
    "        self.ack = flags&1\n",
    "        flags = flags>>1\n",
    "        self.urg = flags&1\n",
    "        self.receive_win = int.from_bytes(self.byte_info[48:50], byteorder='big')\n",
    "        self.checksum    = int.from_bytes(self.byte_info[50:52], byteorder='big')\n",
    "        self.urgent      = int.from_bytes(self.byte_info[52:54], byteorder='big')\n",
    "        self.payload     = len(self.byte_info[34+packet.head_len:])\n",
    "        \n",
    "        \n",
    "    def parse_window_scale(self):\n",
    "        '''shift window size is typically 14. so the scaling is 2^14 = 16384\n",
    "        '''\n",
    "        shift = int.from_bytes(self.byte_info[73:74], byteorder='big')\n",
    "        self.scale = 1<<shift\n",
    "\n",
    "        \n",
    "    def __str__(self):\n",
    "        string = 'Source Port #  = {}\\n'.format(self.source_port)\n",
    "        string = string + 'Dest Port #    = {}\\n'.format(self.dest_port)\n",
    "        string = string + 'Sequence #     = {}\\n'.format(self.sequence_num)\n",
    "        string = string + 'Ackownledge #  = {}\\n'.format(self.ack_num)\n",
    "        string = string + 'Header length  = {}\\n'.format(self.head_len)\n",
    "        string = string + 'URG({}) ACK({}) PSH({})\\n'.format(self.urg, self.ack, self.psh)\n",
    "        string = string + 'RST({}) SYN({}) FIN({})\\n'.format(self.rst, self.syn, self.fin)\n",
    "        string = string + 'Receive window = {}\\n'.format(self.receive_win)\n",
    "        string = string + 'Checksum       = {}\\n'.format(self.checksum)\n",
    "        string = string + 'Urgent         = {}\\n'.format(self.urgent)\n",
    "        return string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flow:\n",
    "    '''Encapsulate a flow of packets from one port of sender to another port of receiver\n",
    "    \n",
    "    Attributes:\n",
    "        __ID  (int):  private class member identification\n",
    "        ID    (int):  identification of a flow\n",
    "        port1 (int):  a port number\n",
    "        port2 (int):  a port number\n",
    "        flow  (list): a list of Packet\n",
    "        loss_rate (float)\n",
    "        throughput_emp (float): empirical throughput\n",
    "        throughput_the (float): theoretical throuhput\n",
    "        rtt (float): round trip time\n",
    "        counter (int): count the number of packets in this flow\n",
    "        scale (int):   window scaling size\n",
    "        tda (int):     number of triple duplicate ack occurs\n",
    "        timeout (int): number of timeout occurs\n",
    "    '''\n",
    "    __ID = 100\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.ID    = Flow.__ID\n",
    "        Flow.__ID += 1\n",
    "        self.port1 = -1\n",
    "        self.port2 = -1\n",
    "        self.flow  = []\n",
    "        self.loss_rate      = -1\n",
    "        self.throughput_emp = -1\n",
    "        self.throughput_the = -1\n",
    "        self.rtt     = -1\n",
    "        self.counter = 0\n",
    "        self.scale   = 1\n",
    "        print('init a new flow {}'.format(self.ID))\n",
    "        \n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'ID={}  port1={}  port2={}  # of packets={}'.format(self.ID, self.port1, self.port2, self.counter)\n",
    "         \n",
    "    \n",
    "    def set_port(self, packet):\n",
    "        self.port1 = packet.source_port\n",
    "        self.port2 = packet.dest_port\n",
    "        \n",
    "    \n",
    "    def get_packet(self, index):\n",
    "        if index >= 0 and index < len(self.flow):\n",
    "            return self.flow[index]\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    \n",
    "    def add_packet(self, packet):\n",
    "        self.flow.append(packet)\n",
    "        self.counter += 1\n",
    "        \n",
    "        \n",
    "    def compute_throughput(self):\n",
    "        '''Compute the throughput for data sent from source to destination. \n",
    "           To estimate throughput count all data and headers. You need to \n",
    "           figure out how to define throughput in terms of what you are including as part of the throughput estimation.\n",
    "        '''\n",
    "        total_data = 0\n",
    "        for packet in self.flow:\n",
    "            total_data += getattr(packet, 'size')\n",
    "            \n",
    "        start = getattr(self.flow[0], 'time_stamp')\n",
    "        end   = getattr(self.flow[self.counter-1], 'time_stamp')\n",
    "        elapse = end - start\n",
    "        try:\n",
    "            self.throughput_emp = (total_data*8.0)/(elapse*1000000)\n",
    "        except Exception as e:\n",
    "            self.throughput_emp = 0\n",
    "        print('***Flow {}***'.format(self.ID))\n",
    "        print('Throughput is {0:1.5f} Mbps\\n'.format(self.throughput_emp))\n",
    "        \n",
    "        \n",
    "    def compute_loss_rate(self):\n",
    "        '''Compute the loss rate for each flow. \n",
    "           Loss rate is the number of packets not received divided by the number of packets sent.\n",
    "        '''\n",
    "        seq_counter = {}\n",
    "        for packet in self.flow:\n",
    "            seq = getattr(packet, 'sequence_num')\n",
    "            source_port = getattr(packet, 'source_port')  # packet's source port\n",
    "            sender_port = self.port1                      # flow's sender\n",
    "            if seq_counter.get(seq) and source_port == sender_port:\n",
    "                seq_counter[seq] = seq_counter[seq] + 1\n",
    "                #print(seq, seq_counter[seq])\n",
    "            else:\n",
    "                seq_counter[seq] = 1\n",
    "                \n",
    "        total_send = 0\n",
    "        for counter in seq_counter.values():\n",
    "            total_send += counter\n",
    "        retransmission = total_send - len(seq_counter) - 1 \n",
    "        print('***Flow {}***'.format(self.ID))\n",
    "        print('# of loss is {}'.format(retransmission))\n",
    "        print('# of packets send is {}'.format(len(self.flow)))\n",
    "        self.loss_rate = retransmission*1.0/len(self.flow)\n",
    "        print('Therefore, the loss rate is {0:1.6f}\\n'.format(self.loss_rate))\n",
    "        \n",
    "        \n",
    "    def estimateRTT(self):\n",
    "        '''Estimate the average RTT. Now compare your empirical throughput from (b) \n",
    "           and the theoretical throughput (estimated using the formula derived in class). Explain your comparison.\n",
    "        '''\n",
    "        payload = 1448       # 1448 byte is the max amount of payload in a TCP segment\n",
    "        sender_dic = {}      # stony brook  {seq --> packet}\n",
    "        sender_dic_ret = {}  # packets that are retransmitted\n",
    "        receiver_dic = {}    # washington   {ack --> packet}\n",
    "        for packet in self.flow:\n",
    "            source_port = getattr(packet, 'source_port')\n",
    "            if source_port == self.port1:  # sender --> receiver\n",
    "                seq = getattr(packet, 'sequence_num')\n",
    "                if sender_dic.get(seq):    # retransmmision packets appear twice\n",
    "                    sender_dic_ret[seq] = packet\n",
    "                else:\n",
    "                    sender_dic[seq] = packet\n",
    "            else:                          # receiver --> sender\n",
    "                ack = getattr(packet, 'ack_num')\n",
    "                receiver_dic[ack] = packet\n",
    "        \n",
    "        for key in sender_dic_ret:  # when esitmating RTT, we do not consider the retransmission case\n",
    "            sender_dic.pop(key)\n",
    "            \n",
    "        total_time = 0\n",
    "        counter = 0\n",
    "        for ack, ack_packet in receiver_dic.items():\n",
    "            seq = ack - payload\n",
    "            seq_packet = sender_dic.get(seq)\n",
    "            if seq_packet:\n",
    "                time2 = getattr(ack_packet, 'time_stamp')\n",
    "                time1 = getattr(seq_packet, 'time_stamp')\n",
    "                total_time += (time2 - time1)\n",
    "                counter += 1\n",
    "        self.rtt = total_time/counter\n",
    "        print('***Flow {}***'.format(self.ID))\n",
    "        print('Estimated RTT is {0:1.5f} second'.format(self.rtt))\n",
    "        try:\n",
    "            self.throughput_the = (math.sqrt(3/2)*1460*8)/(self.rtt*math.sqrt(self.loss_rate))\n",
    "            print('Theoretical throughput is {0:1.5f} Mbps\\n'.format(self.throughput_the/1000000))\n",
    "        except ZeroDivisionError as ze:\n",
    "            print('Theoretical throughput is infinity')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            ÃŸ\n",
    "         \n",
    "    def compute_dta_timeout(self):\n",
    "        '''Compute the number of times a retransmission occurred due to triple duplicate ack \n",
    "           and the number of time a retransmission occurred due to timeout \n",
    "           (as before, determine if you need to do it at the sender or the receiver)\n",
    "        '''\n",
    "        sender_dic = {}      # stony brook  {seq --> [packet]}\n",
    "        receiver_dic = {}    # washington   {ack --> [packet]}\n",
    "        for packet in self.flow:  # divide the packets in the flow into two dict\n",
    "            source_port = getattr(packet, 'source_port')\n",
    "            if source_port == self.port1:   # sender's packet\n",
    "                seq = getattr(packet, 'sequence_num')\n",
    "                packet_list = sender_dic.get(seq)\n",
    "                if packet_list:\n",
    "                    packet_list.append(packet)\n",
    "                else:\n",
    "                    sender_dic[seq] = [packet]\n",
    "            else:                           # receiver's packet\n",
    "                ack = getattr(packet, 'ack_num')\n",
    "                packet_list = receiver_dic.get(ack)\n",
    "                if packet_list:\n",
    "                    packet_list.append(packet)\n",
    "                else:\n",
    "                    receiver_dic[ack] = [packet]\n",
    "                    \n",
    "        retransmit_dic = {}   # {seq --> [packet]}\n",
    "        for seq, packet_list in sender_dic.items():  # get the retrasmitted packets\n",
    "            if len(packet_list) > 1:\n",
    "                retransmit_dic[seq] = packet_list\n",
    "                \n",
    "        total_retransmission = len(retransmit_dic) - 1   # minus the third handshake and the one right after it\n",
    "        tda_counter = 0  # triple duplicate ack counter\n",
    "        \n",
    "        for seq, packet_list in retransmit_dic.items():\n",
    "            ack = seq\n",
    "            timestamp_1 = getattr(packet_list[0], 'time_stamp')  # from data, oberserve no retransmission twice\n",
    "            timestamp_2 = getattr(packet_list[1], 'time_stamp')\n",
    "            packet_list = receiver_dic.get(ack)\n",
    "            if packet_list:\n",
    "                ack_counter = 0\n",
    "                for packet in packet_list:\n",
    "                    timestamp = getattr(packet, 'time_stamp')\n",
    "                    if timestamp > timestamp_1 and timestamp < timestamp_2:\n",
    "                        ack_counter += 1\n",
    "                    if ack_counter >= 3:    # Mark: issue here. one ack plus triple ack, so need to be bigger than 3\n",
    "                        tda_counter += 1\n",
    "                        break\n",
    "                        \n",
    "        self.tda = tda_counter\n",
    "        self.timeout = total_retransmission - self.tda  # two reasons of retransmission: TDA or timeout\n",
    "        print('***Flow {}***'.format(self.ID))\n",
    "        print('# of triple duplicate ack = {}'.format(self.tda))\n",
    "        print('# of timeout = {}\\n'.format(self.timeout))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FlowManager:\n",
    "    '''Manage some flows\n",
    "    \n",
    "    Attributes:\n",
    "        flow_list (list): an list(array) of Flow\n",
    "        flow_info (dict): a dict { ID : (index, port1, port2) }\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.flow_list = []\n",
    "        self.flow_info = {}\n",
    "        \n",
    "        \n",
    "    def add_packet(self, packet):\n",
    "        '''Add a packet to the flow it belongs to. \n",
    "           If the flow does not exit, then create a new one.\n",
    "           \n",
    "        Args:\n",
    "            packet (Packet)\n",
    "        '''\n",
    "        index = self.where_is_packet(packet)\n",
    "        if index == -1:  # this is a \"new packet\": the packet does not belong to any existed flow\n",
    "            new_flow = Flow()\n",
    "            new_flow.set_port(packet)\n",
    "            new_flow.add_packet(packet)\n",
    "            self.add_flow(new_flow)\n",
    "        else:            # this packet belongs to an existed flow\n",
    "            self.flow_list[index].add_packet(packet)\n",
    "    \n",
    "    \n",
    "    def add_flow(self, flow):\n",
    "        '''Add a new flow into FlowManager\n",
    "        \n",
    "        Args:\n",
    "            flow (Flow): a new flow to be added to the flow manager\n",
    "        '''\n",
    "        index = len(self.flow_list)\n",
    "        self.flow_list.append(flow)\n",
    "        ID  = getattr(flow, 'ID')\n",
    "        port1 = getattr(flow, 'port1')\n",
    "        port2 = getattr(flow, 'port2')\n",
    "        self.flow_info[ID] = (index, port1, port2)\n",
    "        \n",
    "    \n",
    "    def where_is_packet(self, packet):\n",
    "        '''Return the flow's index to which a packet belongs\n",
    "        \n",
    "        Args:\n",
    "            packet (Packet): a packet\n",
    "        \n",
    "        Return:\n",
    "            (int): index \n",
    "        '''\n",
    "        source_port = getattr(packet, 'source_port')\n",
    "        dest_port = getattr(packet, 'dest_port')\n",
    "        for ID, info in self.flow_info.items():\n",
    "            if (source_port == info[1] and dest_port == info[2]) or (source_port == info[2] and dest_port == info[1]):\n",
    "                return info[0]\n",
    "        else:\n",
    "            return -1\n",
    "        \n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.flow_list)\n",
    "    \n",
    "    \n",
    "    def get_flow(self, ID):\n",
    "        '''Get a flow according to its ID\n",
    "        \n",
    "        Args:\n",
    "            flow (Flow): Identification number\n",
    "        '''\n",
    "        flow_info = self.flow_info.get(ID)\n",
    "        if flow_info:\n",
    "            index = flow_info[0]\n",
    "            return self.flow_list[index]\n",
    "        return None\n",
    "            \n",
    "            \n",
    "    def partA_b(self):\n",
    "        print('\\n\\n\\nPART A(b)\\n')\n",
    "        for flow in self.flow_list:\n",
    "            flow.compute_throughput()\n",
    "        \n",
    "    \n",
    "    def partA_c(self):\n",
    "        print('\\n\\n\\nPART A(c)\\n')\n",
    "        print('# of loss equals # of retransmission, since when we retransmit, we assume the packet is loss.\\n')\n",
    "        for flow in self.flow_list:\n",
    "            flow.compute_loss_rate()\n",
    "            \n",
    "    \n",
    "    def partA_d(self):\n",
    "        print('\\n\\n\\nPART A(d)\\n')\n",
    "        for flow in self.flow_list:\n",
    "            flow.estimateRTT()\n",
    "        print('\\nTheoretical throughput < emperical throughput.')\n",
    "        print('One reason is that when using the formula, we assume there is no time out.')\n",
    "        print('However, from wireshark we see some timeout. When timeout occurs, we go to slow start. This explains why.')\n",
    "        \n",
    "    \n",
    "    def partB_2(self):\n",
    "        print('\\n\\n\\nPART B(2)\\n')\n",
    "        for flow in self.flow_list:\n",
    "            flow.compute_dta_timeout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('wh_traffic_remote.pcap', 'rb')\n",
    "pcap = dpkt.pcap.Reader(f)\n",
    "packets_bytes = pcap.readpkts()\n",
    "\n",
    "flow_manager = FlowManager()\n",
    "\n",
    "packets = []\n",
    "for packet_bytes in packets_bytes:\n",
    "    packet = Packet(packet_bytes)\n",
    "    packet.parse_byte_info()\n",
    "    flow_manager.add_packet(packet)\n",
    "    packets.append(packet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for flow in flow_manager.flow_list:\n",
    "    print(flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_manager.partA_b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_manager.partA_c()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_manager.partA_b()\n",
    "flow_manager.partA_c()\n",
    "flow_manager.partA_d()\n",
    "\n",
    "flow_manager.partB_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
